{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6633a8d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting polygon-api-client\n",
      "  Using cached polygon_api_client-1.10.1-py3-none-any.whl (39 kB)\n",
      "Collecting websockets<12.0,>=10.3\n",
      "  Using cached websockets-11.0.3-cp39-cp39-macosx_11_0_arm64.whl (121 kB)\n",
      "Collecting certifi<2023.0.0,>=2022.5.18\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Collecting urllib3<2.0.0,>=1.26.9\n",
      "  Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "Installing collected packages: websockets, urllib3, certifi, polygon-api-client\n",
      "  Attempting uninstall: websockets\n",
      "    Found existing installation: websockets 11.0.3\n",
      "    Uninstalling websockets-11.0.3:\n",
      "      Successfully uninstalled websockets-11.0.3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.16\n",
      "    Uninstalling urllib3-1.26.16:\n",
      "      Successfully uninstalled urllib3-1.26.16\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2022.12.7\n",
      "    Uninstalling certifi-2022.12.7:\n",
      "      Successfully uninstalled certifi-2022.12.7\n",
      "  Attempting uninstall: polygon-api-client\n",
      "    Found existing installation: polygon-api-client 1.10.1\n",
      "    Uninstalling polygon-api-client-1.10.1:\n",
      "      Successfully uninstalled polygon-api-client-1.10.1\n",
      "Successfully installed certifi-2022.12.7 polygon-api-client-1.10.1 urllib3-1.26.16 websockets-11.0.3\n",
      "Requirement already satisfied: requests in /Users/esajor/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/esajor/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/esajor/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/esajor/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/esajor/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: matplotlib in /Users/esajor/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages (3.6.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/esajor/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/esajor/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/esajor/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/esajor/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: numpy>=1.19 in /Users/esajor/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from matplotlib) (1.23.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/esajor/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/esajor/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/esajor/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from matplotlib) (22.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/esajor/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/esajor/opt/anaconda3/envs/tensorflow/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Import Tensorflow 2.0\n",
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "\n",
    "#Install Stock API Client (forex aggregates not currently implemented however I addressed the issue and waiting for them to get back to me. Using requests for now)\n",
    "!pip install --upgrade --force-reinstall polygon-api-client\n",
    "!pip install requests\n",
    "!pip install matplotlib\n",
    "\n",
    "#Import other packages\n",
    "from polygon import RESTClient\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import functools\n",
    "import csv\n",
    "import glob\n",
    "#from google.colab import drive\n",
    "from tqdm import tqdm\n",
    "from IPython import display as ipythondisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08181f61",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0260fa9b",
   "metadata": {},
   "source": [
    "## **1.1 TWO FUNCTIONS: ONE TO ACCESS POLYGON API, ANOTHER TO CONVERT TIME STAMP FOR A DATA POINT.**\n",
    "From 20010-01 to 2020-12 A total 120 Months.\n",
    "The function access the Polygon API in 1 hour timeframes in a span of a monnth.\n",
    "Each Monthly Batch comes in as a JSON file which is converted to a pandas DataFrame then Converted into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbc56c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_to_datetime(ts) -> str:\n",
    "    return datetime.datetime.fromtimestamp(ts / 1000.0).strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "def print_csv(start, end, year, month):\n",
    "    # API key\n",
    "    key = '7FYtfcFojteNAujTh8pPfFoZnHnCl89E'  \n",
    "\n",
    "    endpoint = 'https://api.polygon.io/v2/aggs/ticker/C:GBPJPY/range/1/hour/{dfrom}/{to}?apiKey={key}&limit=50000'\n",
    "    resp = requests.get(endpoint.format(dfrom = start, to = end, key = key ))\n",
    "\n",
    "    my_dictionary = {'t': [' '], 'o': [0.0] , 'h': [0.0], 'l': [0.0], 'c': [0.0], 'v': [0.0], 'vw': [0.0], 'avgOHLC': [0.0]}\n",
    "\n",
    "    for result in resp.json()['results']:\n",
    "        dt = ts_to_datetime(result[\"t\"])\n",
    "        avgOHLC = (result['o'] + result['h'] + result['l'] + result['c']) / 4\n",
    "\n",
    "        my_dictionary['t'].append(dt)             # Time\n",
    "        my_dictionary['o'].append(result['o'])    # Open Price\n",
    "        my_dictionary['h'].append(result['h'])    # High Price\n",
    "        my_dictionary['l'].append(result['l'])    # Low Price\n",
    "        my_dictionary['c'].append(result['c'])    # Close Price\n",
    "        my_dictionary['v'].append(result['v'])    # Volume\n",
    "        my_dictionary['vw'].append(result['vw'])  # Volume Weighted\n",
    "        my_dictionary['avgOHLC'].append(avgOHLC)  # Average Price\n",
    "\n",
    "    # converts dictionary to pandas DataFrame\n",
    "    df = pd.DataFrame(my_dictionary)            \n",
    "  \n",
    "    filename = \"/drive/My Drive/CSV2/\" + year + \"-\" + month + \".csv\"\n",
    "\n",
    "    # converts pandas DataFrame into a csv file\n",
    "    df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e305dc4",
   "metadata": {},
   "source": [
    "## **1.2 SCRIPT FOR AUTOMATING A TIMELINE OF 10 YEARS MONTHLY API CALLS**\n",
    "Resulting in 120 Monthly CSV Files with each file containing 1 hour data points in a span of a month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35940a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify training data timeline: 10 years\n",
    "# from 2010 to 2020\n",
    "\n",
    "import datetime\n",
    "import calendar\n",
    "\n",
    "year = 2010\n",
    "month = 1\n",
    "\n",
    "for i in range(0, 11):\n",
    "\n",
    "    for j in range(0, 12):\n",
    "        _, num_days = calendar.monthrange(year + i, month + j)\n",
    "\n",
    "        start_day = datetime.date(year + i, month + j, 1)\n",
    "        end_day = datetime.date(year + i, month + j, num_days)\n",
    "\n",
    "        print_csv(start_day, end_day, str(year + i), str(month + j))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc2a947",
   "metadata": {},
   "source": [
    "## **1.3 CONCATENATING ALL 120 MONTHLY CSV FILES INTO ONE CSV FILE.**\n",
    "The resulting csv file has 68,293 data points from 2010-01 to 2020-12 in 1 hour time frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f368769",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "os.chdir('/drive/My Drive/CSV2/')\n",
    "\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "\n",
    "# combines all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "# export to csv\n",
    "combined_csv.to_csv( \"forexDataGBPJYP.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88961b1a",
   "metadata": {},
   "source": [
    "## **1.4 UPLOADING CSV FILE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e25e60e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[1;32m      2\u001b[0m uploaded \u001b[38;5;241m=\u001b[39m files\u001b[38;5;241m.\u001b[39mupload()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ff2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29fd5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4238eda9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af2892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d50423e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a803e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3898cadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ddb58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66ed4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834632f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381423f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de66ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f046121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373788ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4acd29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd1cb92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6e091a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf4603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d055c9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53737475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005fa7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b715cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f009fa5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeffbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204456dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4742826c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e97fea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e971b039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def2868e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
